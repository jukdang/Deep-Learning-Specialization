{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543251fb",
   "metadata": {},
   "source": [
    "# Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4bbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Input, Dropout, LayerNormalization\n",
    "from transformers import DistilBertTokenizerFast #, TFDistilBertModel\n",
    "from transformers import TFDistilBertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f2052",
   "metadata": {},
   "source": [
    "## 1 - Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878421ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, k, d):\n",
    "    \"\"\"\n",
    "    Get the angles for the positional encoding\n",
    "    \n",
    "    Arguments:\n",
    "        pos -- Column vector containing the positions [[0], [1], ...,[N-1]]\n",
    "        k --   Row vector containing the dimension span [[0, 1, 2, ..., d-1]]\n",
    "        d(integer) -- Encoding size\n",
    "    \n",
    "    Returns:\n",
    "        angles -- (pos, d) numpy array \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get i from dimension span k\n",
    "    i = k//2\n",
    "    # Calculate the angles using pos, i and d\n",
    "    angles = pos / 10000**(2*i/d)\n",
    "    \n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba1c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int) -- Maximum number of positions to be encoded \n",
    "        d (int) -- Encoding size \n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding -- (1, position, d_model) A matrix with the positional encodings\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    angle_rads = get_angles(np.array([[x] for x in range(positions)]),\n",
    "                            np.array([x for x in range(d)]),\n",
    "                            d)\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b828ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('d')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae489027",
   "metadata": {},
   "source": [
    "## 2 - Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51d1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(decoder_token_ids):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        decoder_token_ids -- (n, m) matrix\n",
    "    \n",
    "    Returns:\n",
    "        mask -- (n, 1, m) binary tensor\n",
    "    \"\"\"    \n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab80bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Returns an lower triangular matrix filled with ones\n",
    "    \n",
    "    Arguments:\n",
    "        sequence_length -- matrix size\n",
    "    \n",
    "    Returns:\n",
    "        mask -- (size, size) tensor\n",
    "    \"\"\"\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c6f56",
   "metadata": {},
   "source": [
    "## 3 - Self-Attention\n",
    "self-attention can be mathematically expressed as:\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{4}\\\n",
    "$$\n",
    "\n",
    "* $Q$ is the matrix of queries \n",
    "* $K$ is the matrix of keys\n",
    "* $V$ is the matrix of values\n",
    "* $M$ is the optional mask you choose to apply \n",
    "* ${d_k}$ is the dimension of the keys, which is used to scale everything down so the softmax doesn't explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e5b90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead) \n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "    Arguments:\n",
    "        q -- query shape == (..., seq_len_q, depth)\n",
    "        k -- key shape == (..., seq_len_k, depth)\n",
    "        v -- value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable \n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- attention_weights\n",
    "    \"\"\"\n",
    "    \n",
    "    matmul_qk = tf.matmul(q, k.T)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None: # Don't replace this None\n",
    "        scaled_attention_logits += ((1. - mask)  * -1.0e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.keras.activations.softmax(scaled_attention_logits)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656495e0",
   "metadata": {},
   "source": [
    "## 4 - Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5357069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullyConnected(embedding_dim, fully_connected_dim):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(embedding_dim)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "085bd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network. \n",
    "    This archirecture includes a residual connection around each of the two \n",
    "    sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FullyConnected(embedding_dim=embedding_dim,\n",
    "                                  fully_connected_dim=fully_connected_dim)\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        # calculate self-attention\n",
    "        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n",
    "        attn_output = self.mha(x,x,x,mask) # Self attention (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply layer normalization on sum of the input and the attention output to get the  \n",
    "        # output of the multi-head attention layer\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "\n",
    "        # pass the output of the multi-head attention layer\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply dropout layer to ffn output during training\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        \n",
    "        # apply layer normalization on sum of the output from multi-head attention and ffn output to get the\n",
    "        # output of the encoder layer\n",
    "        encoder_layer_out = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        return encoder_layer_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c941720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    encoder Layers\n",
    "        \n",
    "    \"\"\"  \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(input_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.embedding_dim)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            out2 -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \"\"\"\n",
    "        #mask = create_padding_mask(x)\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Pass input through the Embedding layer\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        # Scale embedding by multiplying it by the square root of the embedding dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        # Add the position encoding to embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        # Pass the encoded embedding through a dropout layer\n",
    "        x = self.dropout(x, training=training)\n",
    "        # Pass the output through the stack of encoding layers \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, fully_connected_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdcd0c",
   "metadata": {},
   "source": [
    "## 5 - Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0bd8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The decoder layer is composed by two multi-head attention blocks, \n",
    "    one that takes the new input and uses self-attention, and the other \n",
    "    one that combines it with the output of the encoder, followed by a\n",
    "    fully connected block. \n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "        self.mha2 = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FullyConnected(embedding_dim=embedding_dim,\n",
    "                                  fully_connected_dim=fully_connected_dim)\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Decoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            enc_output --  Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask -- Boolean mask for the target_input\n",
    "            padding_mask -- Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            out3 -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attn_weights_block1 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "            attn_weights_block2 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "        \n",
    "        # enc_output.shape == (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # calculate self-attention and return attention scores as attn_weights_block1.\n",
    "        # Dropout will be applied during training\n",
    "        mult_attn_out1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask, return_attention_scores=True)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # apply layer normalization (layernorm1) to the sum of the attention output and the input\n",
    "        Q1 = self.layernorm1(mult_attn_out1 + x)\n",
    "\n",
    "        # calculate self-attention using the Q from the first block and K and V from the encoder output. \n",
    "        # Dropout will be applied during training\n",
    "        # Return attention scores as attn_weights_block2\n",
    "        mult_attn_out2, attn_weights_block2 = self.mha2(Q1, enc_output, enc_output, padding_mask, return_attention_scores=True)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # apply layer normalization (layernorm2) to the sum of the attention output and the output of the first block\n",
    "        mult_attn_out2 = self.layernorm2(mult_attn_out2 + Q1)  # (batch_size, target_seq_len, fully_connected_dim)\n",
    "                \n",
    "        # pass the output of the second block through a ffn\n",
    "        ffn_output = self.ffn(mult_attn_out2)  # (batch_size, target_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply a dropout layer to the ffn output\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        \n",
    "        # apply layer normalization (layernorm3) to the sum of the ffn output and the output of the second block\n",
    "        out3 = self.layernorm3(ffn_output + mult_attn_out2)  # (batch_size, target_seq_len, fully_connected_dim)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f84291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder is starts by passing the target input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    decoder Layers\n",
    "        \n",
    "    \"\"\" \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(target_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.embedding_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward  pass for the Decoder\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            enc_output --  Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask -- Boolean mask for the target_input\n",
    "            padding_mask -- Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attention_weights - Dictionary of tensors containing all the attention weights\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        # create word embeddings \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # scale embeddings by multiplying by the square root of their dimension\n",
    "        x *= tf.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        \n",
    "        # calculate positional encodings and add to word embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # apply a dropout layer to x\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # use a for loop to pass x through a stack of decoder layers and update attention_weights\n",
    "        for i in range(self.num_layers):\n",
    "            # pass x and the encoder output through a stack of decoder layers and save the attention weights\n",
    "            # of block 1 and 2\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            #update attention_weights dictionary with the attention weights of block 1 and block 2\n",
    "            attention_weights['decoder_layer{}_block1_self_att'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2_decenc_att'.format(i+1)] = block2\n",
    "        \n",
    "        # x.shape == (batch_size, target_seq_len, fully_connected_dim)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308d099",
   "metadata": {},
   "source": [
    "## 6 - Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74e5353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Complete transformer with an Encoder and a Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, \n",
    "               target_vocab_size, max_positional_encoding_input,\n",
    "               max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers=num_layers,\n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               input_vocab_size=input_vocab_size,\n",
    "                               maximum_position_encoding=max_positional_encoding_input,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, \n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               target_vocab_size=target_vocab_size, \n",
    "                               maximum_position_encoding=max_positional_encoding_target,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.final_layer = Dense(target_vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self, input_sentence, output_sentence, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the entire Transformer\n",
    "        Arguments:\n",
    "            input_sentence -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the input sentence\n",
    "            output_sentence -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the output sentence\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            enc_padding_mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "            look_ahead_mask -- Boolean mask for the target_input\n",
    "            dec_padding_mask -- Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            final_output -- Describe me\n",
    "            attention_weights - Dictionary of tensors containing all the attention weights for the decoder\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # call self.encoder with the appropriate arguments to get the encoder output\n",
    "        enc_output = self.encoder(input_sentence, training, enc_padding_mask)  # (batch_size, inp_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # call self.decoder with the appropriate arguments to get the decoder output\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)\n",
    "        dec_output, attention_weights = self.decoder(output_sentence, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        # pass decoder output through a linear layer and softmax\n",
    "        final_output = self.final_layer(dec_output) # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a799e7",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    <b>What you should remember</b>:\n",
    "\n",
    "- The combination of self-attention and convolutional network layers allows of parallization of training and *faster training*.\n",
    "- Self-attention is calculated using the generated query Q, key K, and value V matrices.\n",
    "- Adding positional encoding to word embeddings is an effective way of include sequence information in self-attention calculations. \n",
    "- Multi-head attention can help detect multiple features in your sentence.\n",
    "- Masking stops the model from 'looking ahead' during training, or weighting zeroes too much when processing cropped sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43873a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
